{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "\n",
    "def data_to_csv():\n",
    "    # 获取数据\n",
    "    newsgroups_train = fetch_20newsgroups(subset = 'train', remove = {'headers', 'footers', 'quotes'})\n",
    "\n",
    "    # 转换数据\n",
    "    df = pd.DataFrame([newsgroups_train.data, newsgroups_train.target.tolist()]).T\n",
    "    df.columns = ['text', 'target']\n",
    "\n",
    "    targets = pd.DataFrame(newsgroups_train.target_names, columns = ['title'])\n",
    "\n",
    "    out = pd.merge(df, targets, left_on = 'target', right_index = True)\n",
    "    out.to_csv('./data/20_newsgroup.csv', index = False)\n",
    "    \n",
    "data_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embeddings\n",
    "import openai, os, tiktoken, backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\"\n",
    "embedding_model = 'text-embedding-ada-002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before null filtering: 11314\n",
      "Number of rows before token number filtering: 11096\n",
      "Number of rows data used: 11044\n"
     ]
    }
   ],
   "source": [
    "embedding_encoding = 'cl100k_base' # this the encoding for text-embedding-ada-002\n",
    "batch_size = 2000\n",
    "max_tokens = 8000\n",
    "\n",
    "df = pd.read_csv('./data/20_newsgroup.csv')\n",
    "print('Number of rows before null filtering:', len(df))\n",
    "df = df[df['text'].isnull() == False]\n",
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(encoding.encode(x)))\n",
    "print('Number of rows before token number filtering:', len(df))\n",
    "df = df[df.n_tokens <= max_tokens]\n",
    "print('Number of rows data used:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def get_embeddings_with_backoff(prompts, engine):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        batch = prompts[i:i+batch_size]\n",
    "        embeddings += get_embeddings(list_of_text = batch, engine = engine)\n",
    "    return embeddings\n",
    "\n",
    "prompts = df.text.tolist()\n",
    "prompt_batches = [prompts[i:i+batch_size] for i in range(0, len(prompts), batch_size)]\n",
    "\n",
    "embeddings = []\n",
    "for batch in prompt_batches:\n",
    "    batch_embeddings = get_embeddings_with_backoff(prompts = batch, engine = embedding_model)\n",
    "    embeddings += batch_embeddings\n",
    "\n",
    "df['embedding'] = embeddings\n",
    "df.to_parquet('./data/20_newsgroup_with_embedding.parquet', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m KMeans\n\u001b[0;32m----> 4\u001b[0m embedding_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_parquet(\u001b[39m\"\u001b[39m\u001b[39m./data/20_newsgroup_with_embedding.parquet\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack(embedding_df\u001b[39m.\u001b[39membedding\u001b[39m.\u001b[39mvalues)\n\u001b[1;32m      7\u001b[0m num_of_clusters \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "embedding_df = pd.read_parquet(\"./data/20_newsgroup_with_embedding.parquet\")\n",
    "\n",
    "matrix = np.vstack(embedding_df.embedding.values)\n",
    "num_of_clusters = 20\n",
    "\n",
    "kmeans = KMeans(n_clusters=num_of_clusters, init=\"k-means++\", n_init=10, random_state=42)\n",
    "kmeans.fit(matrix)\n",
    "labels = kmeans.labels_\n",
    "embedding_df[\"cluster\"] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>count</th>\n",
       "      <th>rank1</th>\n",
       "      <th>rank1_count</th>\n",
       "      <th>rank2</th>\n",
       "      <th>rank2_count</th>\n",
       "      <th>first_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>571</td>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>456</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>36.0</td>\n",
       "      <td>79.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>503</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>189.0</td>\n",
       "      <td>56.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1199</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>456</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>400.0</td>\n",
       "      <td>38.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>562</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>436</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>7.0</td>\n",
       "      <td>77.58%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>499</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>428</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>27.0</td>\n",
       "      <td>85.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>700</td>\n",
       "      <td>talk.politics.misc</td>\n",
       "      <td>266</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>152.0</td>\n",
       "      <td>38.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>84</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>8</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>495</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>487</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>427</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>464</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>340</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>31.0</td>\n",
       "      <td>73.28%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>296</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>254</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>361</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>348</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>396</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>381</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>591</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>61</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.32%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>439</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>416</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>260</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>150</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>45.0</td>\n",
       "      <td>57.69%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>849</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>350</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>34.0</td>\n",
       "      <td>41.22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>502</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>489</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.41%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>933</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>103</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>461</td>\n",
       "      <td>comp.windows.x</td>\n",
       "      <td>428</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.84%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster  count                     rank1  rank1_count   \n",
       "0         0    571              misc.forsale          456  \\\n",
       "1         1    895    soc.religion.christian          503   \n",
       "2         2   1199  comp.sys.ibm.pc.hardware          456   \n",
       "3         3    562                 rec.autos          436   \n",
       "4         4    499     talk.politics.mideast          428   \n",
       "5         5    700        talk.politics.misc          266   \n",
       "6         6     84   comp.os.ms-windows.misc            8   \n",
       "7         7    495        rec.sport.baseball          478   \n",
       "8         8    487                 sci.space          427   \n",
       "9         9    464           sci.electronics          340   \n",
       "10       10    296        talk.politics.guns          254   \n",
       "11       11    361           rec.motorcycles          348   \n",
       "12       12    396                 sci.crypt          381   \n",
       "13       13    591           sci.electronics           61   \n",
       "14       14    439                   sci.med          416   \n",
       "15       15    260        talk.politics.guns          150   \n",
       "16       16    849             comp.graphics          350   \n",
       "17       17    502          rec.sport.hockey          489   \n",
       "18       18    933           rec.motorcycles          103   \n",
       "19       19    461            comp.windows.x          428   \n",
       "\n",
       "                    rank2  rank2_count first_percentage  \n",
       "0   comp.sys.mac.hardware         36.0           79.86%  \n",
       "1             alt.atheism        189.0           56.20%  \n",
       "2   comp.sys.mac.hardware        400.0           38.03%  \n",
       "3   comp.sys.mac.hardware          7.0           77.58%  \n",
       "4             alt.atheism         27.0           85.77%  \n",
       "5             alt.atheism        152.0           38.00%  \n",
       "6   comp.sys.mac.hardware          8.0            9.52%  \n",
       "7                       0          0.0           96.57%  \n",
       "8             alt.atheism          2.0           87.68%  \n",
       "9   comp.sys.mac.hardware         31.0           73.28%  \n",
       "10     talk.religion.misc          5.0           85.81%  \n",
       "11            alt.atheism          1.0           96.40%  \n",
       "12  comp.sys.mac.hardware          1.0           96.21%  \n",
       "13  comp.sys.mac.hardware         28.0           10.32%  \n",
       "14            alt.atheism          1.0           94.76%  \n",
       "15     talk.religion.misc         45.0           57.69%  \n",
       "16  comp.sys.mac.hardware         34.0           41.22%  \n",
       "17                      0          0.0           97.41%  \n",
       "18            alt.atheism         80.0           11.04%  \n",
       "19  comp.sys.mac.hardware          1.0           92.84%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 统计每一个cluster的数量\n",
    "new_df = embedding_df.groupby('cluster')['cluster'].count().reset_index(name = 'count')\n",
    "\n",
    "# 统计这个cluster里最多的分类的数量\n",
    "title_count = embedding_df.groupby(['cluster', 'title']).size().reset_index(name  = 'title_count')\n",
    "first_titles = title_count.groupby('cluster').apply(lambda x: x.nlargest(1, columns=['title_count']))\n",
    "first_titles = first_titles.reset_index(drop = True)\n",
    "new_df = pd.merge(new_df, first_titles[['cluster', 'title', 'title_count']], on = 'cluster', how = 'left')\n",
    "new_df = new_df.rename(columns = {'title': 'rank1', 'title_count':'rank1_count'})\n",
    "\n",
    "# 统计这个cluster里第二多的分类的数量\n",
    "second_titles = title_count[~title_count['title'].isin(first_titles['title'])]\n",
    "second_titles = second_titles.groupby('cluster').apply(lambda x: x.nlargest(1, columns=['title_count']))\n",
    "second_titles = second_titles.reset_index(drop=True)\n",
    "new_df = pd.merge(new_df, second_titles[['cluster', 'title', 'title_count']], on='cluster', how='left')\n",
    "new_df = new_df.rename(columns={'title': 'rank2', 'title_count': 'rank2_count'})\n",
    "new_df.fillna(0, inplace=True)\n",
    "new_df['per_1'] = (new_df['rank1_count'] / new_df['count']).map(lambda x: '{:.2%}'.format(x))\n",
    "new_df['per_1_2'] = ((new_df['rank1_count'] + new_df['rank2_count'])/ new_df['count']).map(lambda x: '{:.2%}'.format(x))\n",
    "# new_df['first_percentage'] = (new_df['rank1_count'] / new_df['count']).map(lambda x: '{:.2%}'.format(x))\n",
    "# 将缺失值替换为 0\n",
    "new_df.fillna(0, inplace=True)\n",
    "# 输出结果\n",
    "display(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0, Rank 1: misc.forsale, Theme: 电子产品出售\n",
      "Cluster 1, Rank 1: soc.religion.christian, Theme: 宗教信仰的多样性\n",
      "Cluster 2, Rank 1: comp.sys.ibm.pc.hardware, Theme: 电脑硬件\n",
      "Cluster 3, Rank 1: rec.autos, Theme: 汽车维修与维护\n",
      "Cluster 4, Rank 1: talk.politics.mideast, Theme: 中东冲突报道\n",
      "Cluster 5, Rank 1: talk.politics.misc, Theme: 主观价值观\n",
      "Cluster 6, Rank 1: comp.os.ms-windows.misc, Theme: 科技产品\"\"\"\n",
      "Cluster 7, Rank 1: rec.sport.baseball, Theme: 运动员技术分析\n",
      "Cluster 8, Rank 1: sci.space, Theme: 太空探索\n",
      "Cluster 9, Rank 1: sci.electronics, Theme: 电脑硬件和电子设备\n",
      "Cluster 10, Rank 1: talk.politics.guns, Theme: 枪支控制讨论\n",
      "Cluster 11, Rank 1: rec.motorcycles, Theme: 骑行者经验分享\n",
      "Cluster 12, Rank 1: sci.crypt, Theme: 公民权利与加密技术\n",
      "Cluster 13, Rank 1: sci.electronics, Theme: 研究与技术\n",
      "Cluster 14, Rank 1: sci.med, Theme: "
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 4609 tokens (4509 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCluster \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m, Rank 1: \u001b[39m\u001b[39m{\u001b[39;00mcluster_name\u001b[39m}\u001b[39;00m\u001b[39m, Theme:\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m content \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m      9\u001b[0m     embedding_df[embedding_df\u001b[39m.\u001b[39mcluster \u001b[39m==\u001b[39m i]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39msample(items_per_cluster, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     12\u001b[0m     model\u001b[39m=\u001b[39;49mCOMPLETIONS_MODEL,\n\u001b[1;32m     13\u001b[0m     prompt\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'''\u001b[39;49m\u001b[39m我们想要给下面的内容，分组成有意义的类别，以便我们可以对其进行总结。请根据下面这些内容的共同点，总结一个50个字以内的新闻组的名称。比如 “PC硬件”\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m内容:\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m{\u001b[39;49;00mcontent\u001b[39m}\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m新闻组名称：\u001b[39;49m\u001b[39m'''\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m     max_tokens\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m     top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    629\u001b[0m         ),\n\u001b[1;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 4609 tokens (4509 in your prompt; 100 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "\n",
    "items_per_cluster = 10\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "\n",
    "for i in range(num_of_clusters):\n",
    "    cluster_name = new_df[new_df.cluster == i].iloc[0].rank1\n",
    "    print(f\"Cluster {i}, Rank 1: {cluster_name}, Theme:\", end=\" \")\n",
    "\n",
    "    content = \"\\n\".join(\n",
    "        embedding_df[embedding_df.cluster == i].text.sample(items_per_cluster, random_state=42).values\n",
    "    )\n",
    "    response = openai.Completion.create(\n",
    "        model=COMPLETIONS_MODEL,\n",
    "        prompt=f'''我们想要给下面的内容，分组成有意义的类别，以便我们可以对其进行总结。请根据下面这些内容的共同点，总结一个50个字以内的新闻组的名称。比如 “PC硬件”\\n\\n内容:\\n\"\"\"\\n{content}\\n\"\"\"新闻组名称：''',\n",
    "        temperature=0,\n",
    "        max_tokens=100,\n",
    "        top_p=1,\n",
    "    )\n",
    "    print(response[\"choices\"][0][\"text\"].replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0, Rank 1: sci.electronics, 抽样翻译: 我开始研究一些在相当嘈杂的环境中，以及在相当远的距离上传输串行数据的设备，我看到了各种保护RS232收发器（以及其他电路）免受串行线上瞬变的方案。我想知道最佳的做法是什么？这有多必要？据我所知，保护是必要的，特别是如果你计划将电缆路由到一个未知的环境（不受控制）。像信号线和电源线之间的意外短路，甚至闪电等事情都是非常可能的，我不认为你会喜欢看到你的电脑烟消云散的景象！（即使以太网卡也受到保护。我看过我的PC中的一个连接器，它由气体放电管保护！）但是，如果你计划将串行电缆用于内部路由（即在受控环境中），则不需要它们应该是相当安全的。建议：查看RS数据手册。他们有几个RS232收发器，具有过压保护。其中包括LT1080，LT1081和MAX250和MAX251。Maxim应该是绝缘的，但仍需要光耦合器才能工作（不要问我为什么。我以前从未使用过它们。）另一种选择是RS232电涌保护器。 RS目录中列出了两个。如果您需要额外的信息（即库存号），请给我发电子邮件。\n",
      "Cluster 1, Rank 1: comp.sys.ibm.pc.hardware, 抽样翻译: 如果您购买带CD配置的Centris 650，您将获得一台带有内置数学协处理器支持的68RC040处理器的Mac。我的理解是“可选fpu”是指您可以选择购买没有FPU的Centris 650 4/80或其他带有FPU的配置。Apple不提供从非FPU系统升级为FPU系统的服务。而且，目前尚不清楚非FPU系统（68LC040）上的'040处理器是否可以由另一家供应商提供的68RC040替换。苹果公司曾经发出一份备忘录，指出只有非FPU 68LC040处理器的Centris 610无法升级为支持FPU - 根据苹果的备忘录，两种芯片的引脚配置似乎不匹配，因此无法互换（再次，根据苹果的备忘录）。希望有所帮助。\n",
      "Cluster 2, Rank 1: talk.politics.misc, 抽样翻译: 以下内容可以在某个FTP存档中找到，我在这封“大哥大”的恶魔般的备忘录中插入了我的评论：看！这显然是禁止我们自己的螺纹规格的第一步。如果不以牙还牙地抵制这种疯狂，使用我们无畏领袖“慷慨”定义的螺纹以外的螺纹将是一种犯罪。废话！我说！ANSI标准螺纹会有微妙的弱点，让他们的特工更容易拆卸我们的汽车，导致我们的消声器在不合适的时候掉下来。哈！“相信我们”看到了吗？！这是第一步。很明显，我们必须团结起来，写信给你的国会议员！使用“相当好的螺纹”，而不是这种恶魔灵感的ANSI垃圾。保护你使用任何螺纹的宪法权利。游击螺纹活动必须成为日常事务。抵制通用汽车，并用STZ螺纹联合公司的螺丝自己建造汽车。螺丝你，比尔·克林顿！你和你的极权主义暴徒！\n",
      "Cluster 3, Rank 1: rec.sport.baseball, 抽样翻译: 我也是... RBI 是一个毫无价值的统计数据。当然，偷垒也是一样，因为有时候有些跑者会在一个可能会跑的球员前面。当然，投手会根据不同的垒位投出不同的球，所以击球率、长打率和击球率也没有用了。嗯... 我猜全垒打也不算了吧。我的意思是？RBI 可能不是一个完美的统计数据，但没有什么是完美的。没有任何统计数据（或缺乏）能告诉我没有关键时刻的击球手。也许没有任何统计数据能告诉我，但有些人是... 我只知道！！ 8)\n",
      "Cluster 4, Rank 1: comp.os.ms-windows.misc, 抽样翻译: 几个月前，我遇到了严重的内存问题，在Windows中出现了“停止错误消息，检查奇偶校验”。我运行了QA / PLUS，Check It，Diagnose以及几个共享软件内存检查器。我的系统中有8兆SIMM。这些商店购买/共享软件诊断工具要么运行正常没有错误，要么在我无法放置在内存芯片上的某个地址上发现错误。出于绝望，我想出了（现在已删除）步骤来找到坏的内存芯片。我发现了2个（道德：永远不要买背面印有“不适用于敏感或关键应用”的内存）。无论如何，我确实使用8兆芯片中的4个组合过滤掉了所有坏的内存芯片，并创建了一个RAM驱动器来进行测试。虽然它没有缓解我在Windows中的奇偶校验错误问题，但我确实以这种方式找到了坏的内存芯片。它从未失败过，为我找到坏的芯片，而商业/共享软件总是让我失望，要么没有发现错误，要么指向我不知道是哪块芯片的地址。PS：今天我的打字水平太糟糕了，我不想再用这个行编辑器了。-大卫\n",
      "Cluster 5, Rank 1: sci.crypt, 抽样翻译: 警察/联邦政府不需要获得您的私钥才能监听蜂窝电话交谈。加密不是端到端的，而是手机到基站 - 它必须是这样，以便蜂窝用户和固定设备可以相互交谈。对于蜂窝到蜂窝的通话，传输在基站解密，传递到另一个基站并重新加密。警察/联邦政府可以听取未加密的通话，前提是他们获得搜查蜂窝提供商设备的令牌。想要破解系统的唯一原因是他们可以在不获得令牌的情况下监听。但是，也许Clipper系统是安全的，他们确实需要一个令牌才能从保管处获取密钥，然后才能使用扫描仪进行监听（参见上面 - 他们不必*必须*走这条路）。我有我的疑虑，但即使是真的，一旦他们拥有密钥，他们将*永远*不再需要令牌来拨打该手机，随时随地都可以监听。 “嗯，法官，看来他不是毒贩，所以我们自然会停止监听……”那对英国保罗来说是真的，但我相信他们正在讨论如何使用这个芯片构建端到端加密电话。这*不是*蜂窝（尽管它当然可以按照您的建议在那里使用）\n",
      "Cluster 6, Rank 1: comp.graphics, 抽样翻译: 我需要有关Display PostScript strokeadjust功能的信息。此功能可调整线的端点，以使在低分辨率设备上显示的线看起来更好。PostScript文献在一定程度上解释了这个过程。他们还给出了一个如何在没有strokeadjust的PostScript环境中“模拟”strokeadjust的例子。建议的模拟是使用以下公式修改线的端点坐标：新坐标=（四舍五入（旧坐标-0.25））+0.25这样，我们最终得到所有坐标以“.25”结尾。从阅读中，我认为他们实际上可能做的是：新坐标=（（截断（旧坐标*2））/2）+0.25这样，所有坐标都以“0.25”或“0.75”结尾，取决于哪个更接近。通过与Display PostScript进行实际比较，我发现DPS实际上不是用这两种方法。由于我喜欢DPS的结果比我的东西看起来更好，我想知道是否有人知道DPS是如何做的，愿意/能够告诉我。谢谢！\n",
      "Cluster 7, Rank 1: sci.space, 抽样翻译: 我认为，如果有奖励等，应该有以下“类别”：大公司小公司/公司（根据报告收入？）大政府（国民生产总值等）小政府（或政治影响力或国民生产总值？）大组织（行星协会？等）小组织（许多小型组织..）组织事务可能必须是非营利性的，或者是？当然，这意味着奖金可能会增加。较大的获得更多或？基本上使奖金（总奖金）60亿美元，分配给班级获胜者..更公平？必须建立一个单独的组织来监督活动，裁判等，并监视安全违规（或者不，如果人们想冒自己的生命危险让他们去做？）。\n",
      "Cluster 8, Rank 1: talk.politics.guns, 抽样翻译: 我当时现场观看，并且已经重新观看了几次，从新闻视角来看，只有一个起火点可见，坦克在迎风侧打入，风把火势席卷整个干燥的木结构，几分钟内就烧毁了。受30英里每小时的大风和直升机的影响，火势迅速蔓延。如果有其他火源，它们不可见，也不需要，我观察到的火势就是这样。所有的见证者都是从联邦调查局那里拿工资的。是的，媒体毫无疑问地支持联邦调查局的版本。真可悲。吉姆--jmd@handheld.com\n",
      "Cluster 9, Rank 1: rec.motorcycles, 抽样翻译: 1.在前苏联有一个类似的想法，需要多少军人来安装一个新的电灯？答案是九个：一个坐在桌子上拿着灯，四个拿着桌子转动它，另外四个则以相反的方向绕着桌子跑，以免让第一个感到不舒服（被转动时）。可惜，它缺乏尼克的消息中的那种黑色幽默。2.在我看来，签名应该是这样的：/       _                     __        /  ./_______/_/_______________    /________ /____//___ /      _                  /特使Albert\n",
      "Cluster 10, Rank 1: rec.sport.hockey, 抽样翻译: 嗨，曲棍球迷们。大家好！上周日，在盐湖城，当地的ABC电视台决定不播放曲棍球比赛。节目主管真是个混蛋！不管怎样，我有一个卫星天线，几个曲棍球朋友邀请自己过来看本周日（4月25日）的比赛，但我找不到正确的比赛时间。对于卡尔加里和洛杉矶的比赛，我有时间显示从MDT 11:00到MDT 5:00。现在，我甚至不确定本周日会有哪些比赛，因为ABC搞乱了时间表。我想我应该能从天线上收到三场比赛（MDT 11:00，2:00和5:30），但我不确定。如果有人有时间表，请给我发电子邮件。正如你所看到的，我必须收听rec.sport.hockey，有时很难得到链接。提前谢谢非常感谢附言：英语或法语都可以。罗兰·贝胡宁behunin@oodis01.af.milbehunin@oodis01.hill.af.mil\n",
      "Cluster 11, Rank 1: comp.windows.x, 抽样翻译: 由于xterminals没有NeWS服务器，它们具有速度的本质，因为它们的功能有限：一旦添加NeWS和其他一切，就拥有了工作站。 我听说有一些变通方法，其中一种涉及perl脚本。 我们正试图用不需要NeWS（如ghostview）的程序替换需要NeWS（如pageview）的程序。也许其他人可以详细说明perl变通方法； 我没有个人经验。\n",
      "Cluster 12, Rank 1: talk.politics.mideast, 抽样翻译: 游击队和恐怖分子组织使用的一种“可靠的”方法是：在当地民众中间进行行动，从而迫使对立的“国家”可能会伤害无辜的平民，以搜索，或者为了避免平民死亡而放弃搜索。当然，利用人口作为掩护的人也应该为把无辜的平民拖入危险境地负责。你是在暗示，当游击队利用人口作为掩护时，以色列应该完全放弃吗？所以......最简单的方法是利用无辜者作为护盾，并希望对方尊重无辜的生命？你该死的对，以色列坚持一些“非军事化”或“缓冲”区。它已经忍受了太多年来阿拉伯国家领土发动的攻击，并看到这些国家什么也没做。以色列决定停止这种行动的唯一方法是自己去做，这并不奇怪。什么？所以关于以色列来自邻近阿拉伯国家的攻击可以重新开始？虽然我也希望这种情况发生，但只有当阿拉伯国家表明他们准备承担责任和责任来阻止以色列来自他们领土的游击袭击时，这才会发生。他们必须证明（或提供一些“保证”），以色列不会接受他们的“话”-不要求他们对“反以色列游击队”的容忍态度。天哪，布拉德。你到底是怎么想到联合国部队可以阻止任何事情的？他们只是因为那个国家允许他们进入而驻扎在那里。它可以要求他们随时离开；就像纳赛尔在1956年和1967年所做的那样。既然有这种“限制”，我不认为以色列会更舒服。如果没有阿拉伯国家对和平的真正承诺，以及其他各方提供的具体（而不是智力或政治上的行动）“保证”，联合国对以色列毫无用处（但也许可以作为一个“诡计”？）。也许你知道，对大多数社区来说，有一种感觉，即“我们中的许多人与那些攻击我们的人作斗争而死，要比少数人默默地接受命运而死要好”。但是，如果你要求以色列看到受伤少的意义，我建议你也同样应用于巴勒斯坦，阿拉伯和伊斯兰团体。从以色列的角度来看，“让步”一无所获......除了意识到它已经放弃了“某些东西”，现在只能*希望*对方决定也这样做。话可以通过仅仅这样来收回；要“收回”有形的物品（土地，土地控制权），需要你所说的以色列应该避免的行动。以色列忍受阿拉伯国家领土发动的攻击已有几十年之久，直到通过其对黎巴嫩的入侵才基本上停止了这种现实。整个基础就是你上面所说的：1）以色列会对这些攻击表示愤怒，向有关阿拉伯国家抗议，2）那个国家立即无视整个事件，确信它不能为“私人组织”所犯的罪行负责，3）以色列\n",
      "Cluster 13, Rank 1: sci.med, 抽样翻译: Nutrasweet是一种合成甜味剂，比糖甜几千倍。有些人担心人体分解Nutrasweet时产生的化学物质。据认为，它会形成甲醛，并且已知会在人体排除物质的降解途径中产生甲醇。真正的问题是甲醇和甲醛的水平是否足够高，以致于造成重大损害，因为它们对活细胞都有毒性。我只能说我不会摄入它。苯丙氨酸不是你要担心的。它是一种氨基酸，每个人都会使用少量的苯丙氨酸来进行蛋白质合成。有些人患有苯丙酮尿症，他们缺少降解这种化合物并排除体外的酶。对他们来说，它会在体内积累，而且在高水平下，这对生长中的神经细胞有毒性。因此，它只是儿童（直到10岁左右）或患有这种疾病的妇女的主要问题。它曾经是婴儿脑损伤的主要原因，但现在可以在出生时轻松检测到，然后只需要避免儿童或怀孕时摄入苯丙氨酸即可。\n",
      "Cluster 14, Rank 1: comp.os.ms-windows.misc, 抽样翻译: "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m cluster_name \u001b[39m=\u001b[39m new_df[new_df\u001b[39m.\u001b[39mcluster \u001b[39m==\u001b[39m i]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mrank1\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCluster \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m, Rank 1: \u001b[39m\u001b[39m{\u001b[39;00mcluster_name\u001b[39m}\u001b[39;00m\u001b[39m, 抽样翻译:\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m content \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m----> 9\u001b[0m     embedding_df[(embedding_df\u001b[39m.\u001b[39;49mcluster \u001b[39m==\u001b[39;49m i) \u001b[39m&\u001b[39;49m (embedding_df\u001b[39m.\u001b[39;49mn_tokens \u001b[39m>\u001b[39;49m \u001b[39m100\u001b[39;49m)]\u001b[39m.\u001b[39;49mtext\u001b[39m.\u001b[39;49msample(items_per_cluster, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mCompletion\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m     12\u001b[0m     model\u001b[39m=\u001b[39mCOMPLETIONS_MODEL,\n\u001b[1;32m     13\u001b[0m     prompt\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'''\u001b[39m\u001b[39m请把下面的内容翻译成中文\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m内容:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mcontent\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m翻译：\u001b[39m\u001b[39m'''\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     top_p\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/pandas/core/generic.py:5858\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   5855\u001b[0m \u001b[39mif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5856\u001b[0m     weights \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39mpreprocess_weights(\u001b[39mself\u001b[39m, weights, axis)\n\u001b[0;32m-> 5858\u001b[0m sampled_indices \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39;49msample(obj_len, size, replace, weights, rs)\n\u001b[1;32m   5859\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(sampled_indices, axis\u001b[39m=\u001b[39maxis)\n\u001b[1;32m   5861\u001b[0m \u001b[39mif\u001b[39;00m ignore_index:\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/pandas/core/sample.py:151\u001b[0m, in \u001b[0;36msample\u001b[0;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid weights: weights sum to zero\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 151\u001b[0m \u001b[39mreturn\u001b[39;00m random_state\u001b[39m.\u001b[39;49mchoice(obj_len, size\u001b[39m=\u001b[39;49msize, replace\u001b[39m=\u001b[39;49mreplace, p\u001b[39m=\u001b[39;49mweights)\u001b[39m.\u001b[39mastype(\n\u001b[1;32m    152\u001b[0m     np\u001b[39m.\u001b[39mintp, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    153\u001b[0m )\n",
      "File \u001b[0;32mmtrand.pyx:928\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "\n",
    "items_per_cluster = 1\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "\n",
    "for i in range(num_of_clusters):\n",
    "    cluster_name = new_df[new_df.cluster == i].iloc[0].rank1\n",
    "    print(f\"Cluster {i}, Rank 1: {cluster_name}, 抽样翻译:\", end=\" \")\n",
    "\n",
    "    content = \"\\n\".join(\n",
    "        embedding_df[(embedding_df.cluster == i) & (embedding_df.n_tokens > 100)].text.sample(items_per_cluster, random_state=42).values\n",
    "    )\n",
    "    response = openai.Completion.create(\n",
    "        model=COMPLETIONS_MODEL,\n",
    "        prompt=f'''请把下面的内容翻译成中文\\n\\n内容:\\n\"\"\"\\n{content}\\n\"\"\"翻译：''',\n",
    "        temperature=0,\n",
    "        max_tokens=2000,\n",
    "        top_p=1,\n",
    "    )\n",
    "    print(response[\"choices\"][0][\"text\"].replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self, prompt, num_of_round):\n",
    "        self.prompt = prompt\n",
    "        self.num_of_round = num_of_round\n",
    "        self.messages = []\n",
    "        self.messages.append({'role':'system', 'content': self.prompt})\n",
    "    \n",
    "    def ask(self, question):\n",
    "        try:\n",
    "            self.messages.append({'role':'user', 'content': question})\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model='gpt-3.5-turbo',\n",
    "                messages = self.messages,\n",
    "                temperature = 0.5,\n",
    "                max_tokens = 2048,\n",
    "                top_p = 1,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return e\n",
    "        \n",
    "        message  = response['choices'][0]['message']['content']\n",
    "        self.messages.append({'role':'assistant', 'content': message})\n",
    "\n",
    "        if len(self.messages) > self.num_of_round*2 + 1:\n",
    "            del self.messages[1:3] # Remove the first round conversation left\n",
    "        return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User和Assistant聊了关于正当防卫和防卫过当的内容。User询问了什么是正当防卫，Assistant回答了这是一种在必要时出于保护自身及他人公共利益的防御行为，法律中可以免除或减轻犯罪责任，但也有限制。User进一步问了防卫过当，Assistant\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = \"\"\"User : 你是谁？\n",
    "Assistant : 我是一个AI语言模型，专门用于回答各种问题，包括法律问题。\n",
    "\n",
    "User : 请问什么是正当防卫？\n",
    "Assistant : 正当防卫是指在必要时为了保护自己、他人或者国家公共利益而采取的防御行为。在我国法律中，对于正当防卫的情况，法律规定可以免除或减轻犯罪责任。但是，正当防卫也有限制，必须符合法律规定的情形和条件，否则可能构成违法犯罪行为。\n",
    "\n",
    "User : 那防卫过当呢？\n",
    "Assistant : 防卫过当是指在正当防卫行为中，因过度防卫而超出了必要限度，对袭击者造成了严重伤害或者死亡的行为。在我国法律中，防卫过当是不被允许的，因为它已经超出了必要的防卫范围，可能构成过失犯罪或者故意犯罪。如果行为构成犯罪，防卫人需要承担相应的法律责任。\n",
    "\"\"\"\n",
    "\n",
    "def summarize(text, max_tokens=200):\n",
    "    response = openai.Completion.create(\n",
    "        model=COMPLETIONS_MODEL,\n",
    "        prompt=text + \"\\n\\n请总结一下上面User和Assistant聊了些什么：\\n\",\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"text\"]\n",
    "\n",
    "summarized = summarize(history)\n",
    "print(summarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User : 那恶意挑衅呢？\n",
      "Assistant : 恶意挑衅是指他人以言语、行为等方式故意挑衅、侮辱或者侵犯他人人身权利，如果被挑衅者出于自卫而采取防卫行为，且防卫行为符合正当防卫的要求，那么这种防卫行为也是合法的。但是如果被挑衅者的防卫行为明显超出了正当防卫的必要性和适度性，那么就可能构成防卫过当，需要承担相应的法律责任。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = summarized + \"\\n\\n请你根据已经聊了的内容，继续对话：\"\n",
    "conversation = Conversation(prompt, 5)\n",
    "\n",
    "question = \"那恶意挑衅呢？\"\n",
    "answer = conversation.ask(question)\n",
    "print(\"User : %s\" % question)\n",
    "print(\"Assistant : %s\\n\" % answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User : 那恶意挑衅呢？\n",
      "Assistant : 恶意挑衅是指有人故意挑衅、侮辱或者攻击别人，这种行为是不应该被容忍的。如果我们遇到这种情况，我们应该要保持冷静，不要过度激动或者反击，可以采取一些有效的措施来应对，比如报警或者向相关机构举报。另外，我们也可以通过教育和宣传来提高公众对于恶意挑衅的认识，让更多人知道这种行为的危害性和不可取性。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conversation = Conversation(\"请你根据已经聊了的内容，继续对话：\", 5)\n",
    "\n",
    "question = \"那恶意挑衅呢？\"\n",
    "answer = conversation.ask(question)\n",
    "print(\"User : %s\" % question)\n",
    "print(\"Assistant : %s\\n\" % answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
