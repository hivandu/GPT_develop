{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from openai.embeddings_utils import get_embedding, get_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "open.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model parameters\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embedding_encoding = \"cl100k_base\" # this the encoding for text-embeddings-ada-002\n",
    "max_tokens = 8000 # the maximum for text-embedding-ada-002 is 8191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/7cr1cmpn7v5b3x20_9wz8m740000gn/T/ipykernel_48782/3103381717.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv('./data/toutiao_cat_data.txt', sep='_!_', names=['id','code','category','title','keywords'])\n"
     ]
    }
   ],
   "source": [
    "# import toutiao_cat_data.txt to pd dataframe;\n",
    "df = pd.read_csv('/Volumes/data/GPT/data/toutiao_cat_data.txt', sep='_!_', names=['id','code','category','title','keywords'])\n",
    "df = df.fillna(\"\")\n",
    "df['combined'] = (\n",
    "    \"标题: \" + df.title.str.strip() + \"; 关键字： \" + df.keywords.str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines of text before filtering:  382688\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines of text before filtering: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "# omit reviews that are too long to embed\n",
    "\n",
    "df['n_tokens'] = df.combined.apply(lambda x: len(encoding.encode(x)))\n",
    "df = df[df.n_tokens <= max_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines of text after filtering:  382688\n"
     ]
    }
   ],
   "source": [
    "print('lines of text after filtering: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x2907c2800 state=finished raised AuthenticationError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/embeddings_utils.py:23\u001b[0m, in \u001b[0;36mget_embedding\u001b[0;34m(text, engine)\u001b[0m\n\u001b[1;32m     21\u001b[0m text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m[text], engine\u001b[39m=\u001b[39;49mengine)[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_resources/embedding.py:34\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     36\u001b[0m     \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[39m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:107\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    105\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MAX_TIMEOUT\n\u001b[0;32m--> 107\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[1;32m    108\u001b[0m     api_key,\n\u001b[1;32m    109\u001b[0m     api_base\u001b[39m=\u001b[39;49mapi_base,\n\u001b[1;32m    110\u001b[0m     api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[1;32m    111\u001b[0m     api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[1;32m    112\u001b[0m     organization\u001b[39m=\u001b[39;49morganization,\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    114\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_requestor.py:85\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[0;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[0;32m---> 85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[1;32m     87\u001b[0m     ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[1;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m api_type\n\u001b[1;32m     89\u001b[0m     \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[1;32m     90\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[1;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m     )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# randomly sample 1k rows\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_1k \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msample(\u001b[39m1000\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m df_1k[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_1k\u001b[39m.\u001b[39;49mcombined\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x : get_embedding(x, engine\u001b[39m=\u001b[39;49membedding_model))\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/pandas/core/series.py:4626\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4516\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4517\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4518\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4521\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4522\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4523\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4524\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4525\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4624\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4625\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4626\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1077\u001b[0m             values,\n\u001b[1;32m   1078\u001b[0m             f,\n\u001b[1;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# randomly sample 1k rows\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_1k \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msample(\u001b[39m1000\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m df_1k[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_1k\u001b[39m.\u001b[39mcombined\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x : get_embedding(x, engine\u001b[39m=\u001b[39;49membedding_model))\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[1;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x2907c2800 state=finished raised AuthenticationError>]"
     ]
    }
   ],
   "source": [
    "\n",
    "# randomly sample 1k rows\n",
    "df_1k = df.sample(1000, random_state=42)\n",
    "\n",
    "df_1k[\"embedding\"] = df_1k.combined.apply(lambda x : get_embedding(x, engine=embedding_model))\n",
    "df_1k.to_csv(\"/Volumes/data/GPT/data/toutiao_cat_data_10k_with_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def get_embedding_with_backoff(**kwargs):\n",
    "    return get_embedding(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x2878cf040 state=finished raised AuthenticationError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/embeddings_utils.py:23\u001b[0m, in \u001b[0;36mget_embedding\u001b[0;34m(text, engine)\u001b[0m\n\u001b[1;32m     21\u001b[0m text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m[text], engine\u001b[39m=\u001b[39;49mengine)[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_resources/embedding.py:34\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     36\u001b[0m     \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[39m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:107\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    105\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MAX_TIMEOUT\n\u001b[0;32m--> 107\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[1;32m    108\u001b[0m     api_key,\n\u001b[1;32m    109\u001b[0m     api_base\u001b[39m=\u001b[39;49mapi_base,\n\u001b[1;32m    110\u001b[0m     api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[1;32m    111\u001b[0m     api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[1;32m    112\u001b[0m     organization\u001b[39m=\u001b[39;49morganization,\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    114\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_requestor.py:85\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[0;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[0;32m---> 85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[1;32m     87\u001b[0m     ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[1;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m api_type\n\u001b[1;32m     89\u001b[0m     \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[1;32m     90\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[1;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m     )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# randomly sample 10k rows\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_10k \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msample(\u001b[39m10000\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m df_10k[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_10k\u001b[39m.\u001b[39;49mcombined\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x : get_embedding_with_backoff(text\u001b[39m=\u001b[39;49mx, engine\u001b[39m=\u001b[39;49membedding_model))\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/pandas/core/series.py:4626\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4516\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4517\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4518\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4521\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4522\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4523\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4524\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4525\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4624\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4625\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4626\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1077\u001b[0m             values,\n\u001b[1;32m   1078\u001b[0m             f,\n\u001b[1;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# randomly sample 10k rows\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_10k \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msample(\u001b[39m10000\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m df_10k[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_10k\u001b[39m.\u001b[39mcombined\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x : get_embedding_with_backoff(text\u001b[39m=\u001b[39;49mx, engine\u001b[39m=\u001b[39;49membedding_model))\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/backoff/_sync.py:105\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m details \u001b[39m=\u001b[39m {\n\u001b[1;32m     97\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m: target,\n\u001b[1;32m     98\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m: args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39melapsed\u001b[39m\u001b[39m\"\u001b[39m: elapsed,\n\u001b[1;32m    102\u001b[0m }\n\u001b[1;32m    104\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     ret \u001b[39m=\u001b[39m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    106\u001b[0m \u001b[39mexcept\u001b[39;00m exception \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    107\u001b[0m     max_tries_exceeded \u001b[39m=\u001b[39m (tries \u001b[39m==\u001b[39m max_tries_value)\n",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m, in \u001b[0;36mget_embedding_with_backoff\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m@backoff\u001b[39m\u001b[39m.\u001b[39mon_exception(backoff\u001b[39m.\u001b[39mexpo, openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mRateLimitError)\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_embedding_with_backoff\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m----> 3\u001b[0m     \u001b[39mreturn\u001b[39;00m get_embedding(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[1;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x2878cf040 state=finished raised AuthenticationError>]"
     ]
    }
   ],
   "source": [
    "# randomly sample 10k rows\n",
    "df_10k = df.sample(10000, random_state=42)\n",
    "\n",
    "df_10k[\"embedding\"] = df_10k.combined.apply(lambda x : get_embedding_with_backoff(text=x, engine=embedding_model))\n",
    "df_10k.to_csv(\"/Volumes/data/GPT/data/toutiao_cat_data_10k_with_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x287910040 state=finished raised AuthenticationError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/embeddings_utils.py:35\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(list_of_text, engine)\u001b[0m\n\u001b[1;32m     33\u001b[0m list_of_text \u001b[39m=\u001b[39m [text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m list_of_text]\n\u001b[0;32m---> 35\u001b[0m data \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mlist_of_text, engine\u001b[39m=\u001b[39;49mengine)\u001b[39m.\u001b[39mdata\n\u001b[1;32m     36\u001b[0m data \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(data, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m])  \u001b[39m# maintain the same order as input.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_resources/embedding.py:34\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     36\u001b[0m     \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[39m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:107\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    105\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MAX_TIMEOUT\n\u001b[0;32m--> 107\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[1;32m    108\u001b[0m     api_key,\n\u001b[1;32m    109\u001b[0m     api_base\u001b[39m=\u001b[39;49mapi_base,\n\u001b[1;32m    110\u001b[0m     api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[1;32m    111\u001b[0m     api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[1;32m    112\u001b[0m     organization\u001b[39m=\u001b[39;49morganization,\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    114\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_requestor.py:85\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[0;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[0;32m---> 85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[1;32m     87\u001b[0m     ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[1;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m api_type\n\u001b[1;32m     89\u001b[0m     \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[1;32m     90\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[1;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m     )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m embeddings \u001b[39m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m prompt_batches:\n\u001b[0;32m---> 22\u001b[0m     batch_embeddings \u001b[39m=\u001b[39m get_embeddings_with_backoff(prompts\u001b[39m=\u001b[39;49mbatch, engine\u001b[39m=\u001b[39;49membedding_model)\n\u001b[1;32m     23\u001b[0m     embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_embeddings\n\u001b[1;32m     25\u001b[0m df_all[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m embeddings\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/backoff/_sync.py:105\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m details \u001b[39m=\u001b[39m {\n\u001b[1;32m     97\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m: target,\n\u001b[1;32m     98\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m: args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39melapsed\u001b[39m\u001b[39m\"\u001b[39m: elapsed,\n\u001b[1;32m    102\u001b[0m }\n\u001b[1;32m    104\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     ret \u001b[39m=\u001b[39m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    106\u001b[0m \u001b[39mexcept\u001b[39;00m exception \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    107\u001b[0m     max_tries_exceeded \u001b[39m=\u001b[39m (tries \u001b[39m==\u001b[39m max_tries_value)\n",
      "Cell \u001b[0;32mIn[20], line 11\u001b[0m, in \u001b[0;36mget_embeddings_with_backoff\u001b[0;34m(prompts, engine)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(prompts), batch_size):\n\u001b[1;32m     10\u001b[0m     batch \u001b[39m=\u001b[39m prompts[i:i\u001b[39m+\u001b[39mbatch_size]\n\u001b[0;32m---> 11\u001b[0m     embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m get_embeddings(list_of_text\u001b[39m=\u001b[39;49mbatch, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[1;32m     12\u001b[0m \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[1;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x287910040 state=finished raised AuthenticationError>]"
     ]
    }
   ],
   "source": [
    "\n",
    "import backoff\n",
    "from openai.embeddings_utils import get_embeddings\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def get_embeddings_with_backoff(prompts, engine):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        batch = prompts[i:i+batch_size]\n",
    "        embeddings += get_embeddings(list_of_text=batch, engine=engine)\n",
    "    return embeddings\n",
    "\n",
    "# randomly sample 10k rows\n",
    "df_all = df\n",
    "# group prompts into batches of 100\n",
    "prompts = df_all.combined.tolist()\n",
    "prompt_batches = [prompts[i:i+batch_size] for i in range(0, len(prompts), batch_size)]\n",
    "\n",
    "embeddings = []\n",
    "for batch in prompt_batches:\n",
    "    batch_embeddings = get_embeddings_with_backoff(prompts=batch, engine=embedding_model)\n",
    "    embeddings += batch_embeddings\n",
    "\n",
    "df_all[\"embedding\"] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import backoff\n",
    "from openai.embeddings_utils import get_embeddings\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def get_embeddings_with_backoff(prompts, engine):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        batch = prompts[i:i+batch_size]\n",
    "        embeddings += get_embeddings(list_of_text=batch, engine=engine)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x2879c1360 state=finished raised AuthenticationError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/embeddings_utils.py:35\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(list_of_text, engine)\u001b[0m\n\u001b[1;32m     33\u001b[0m list_of_text \u001b[39m=\u001b[39m [text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m list_of_text]\n\u001b[0;32m---> 35\u001b[0m data \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mlist_of_text, engine\u001b[39m=\u001b[39;49mengine)\u001b[39m.\u001b[39mdata\n\u001b[1;32m     36\u001b[0m data \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(data, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m])  \u001b[39m# maintain the same order as input.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_resources/embedding.py:34\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     36\u001b[0m     \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[39m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:107\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    105\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MAX_TIMEOUT\n\u001b[0;32m--> 107\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[1;32m    108\u001b[0m     api_key,\n\u001b[1;32m    109\u001b[0m     api_base\u001b[39m=\u001b[39;49mapi_base,\n\u001b[1;32m    110\u001b[0m     api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[1;32m    111\u001b[0m     api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[1;32m    112\u001b[0m     organization\u001b[39m=\u001b[39;49morganization,\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    114\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/api_requestor.py:85\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[0;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[0;32m---> 85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[1;32m     87\u001b[0m     ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[1;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m api_type\n\u001b[1;32m     89\u001b[0m     \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[1;32m     90\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/openai/util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[1;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m     )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m embeddings \u001b[39m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m prompt_batches:\n\u001b[0;32m---> 11\u001b[0m     batch_embeddings \u001b[39m=\u001b[39m get_embeddings_with_backoff(prompts\u001b[39m=\u001b[39;49mbatch, engine\u001b[39m=\u001b[39;49membedding_model)\n\u001b[1;32m     12\u001b[0m     embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_embeddings\n\u001b[1;32m     14\u001b[0m df_all[\u001b[39m'\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m embeddings\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/backoff/_sync.py:105\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m details \u001b[39m=\u001b[39m {\n\u001b[1;32m     97\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m: target,\n\u001b[1;32m     98\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m: args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39melapsed\u001b[39m\u001b[39m\"\u001b[39m: elapsed,\n\u001b[1;32m    102\u001b[0m }\n\u001b[1;32m    104\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     ret \u001b[39m=\u001b[39m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    106\u001b[0m \u001b[39mexcept\u001b[39;00m exception \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    107\u001b[0m     max_tries_exceeded \u001b[39m=\u001b[39m (tries \u001b[39m==\u001b[39m max_tries_value)\n",
      "Cell \u001b[0;32mIn[22], line 11\u001b[0m, in \u001b[0;36mget_embeddings_with_backoff\u001b[0;34m(prompts, engine)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(prompts), batch_size):\n\u001b[1;32m     10\u001b[0m     batch \u001b[39m=\u001b[39m prompts[i:i\u001b[39m+\u001b[39mbatch_size]\n\u001b[0;32m---> 11\u001b[0m     embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m get_embeddings(list_of_text\u001b[39m=\u001b[39;49mbatch, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[1;32m     12\u001b[0m \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/gpt/lib/python3.10/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[1;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x2879c1360 state=finished raised AuthenticationError>]"
     ]
    }
   ],
   "source": [
    "# randomly sample 10k rows\n",
    "df_all = df\n",
    "\n",
    "# group prompts into batches of 100\n",
    "prompts = df_all.combined.tolist()\n",
    "prompt_batches = [prompts[i:i+batch_size] for i in range(0, len(prompts), batch_size)]\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for batch in prompt_batches:\n",
    "    batch_embeddings = get_embeddings_with_backoff(prompts=batch, engine=embedding_model)\n",
    "    embeddings += batch_embeddings\n",
    "\n",
    "df_all['embedding'] = embeddings\n",
    "df_all.to_parquest('/Volumes/data/GPT/data/toutiao_cat_data_all_with_embeddings.parquet', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "training_data = pd.read_parquet('/Volumes/data/GPT/data/toutiao_cat_data_all_with_embeddings.parquet')\n",
    "training_data.head()\n",
    "\n",
    "df = training_data.sample(50000, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    list(df.embedding.values), df.category, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "  news_agriculture       0.82      0.86      0.84       495\n",
      "          news_car       0.89      0.94      0.91       895\n",
      "      news_culture       0.85      0.77      0.81       741\n",
      "          news_edu       0.86      0.89      0.88       708\n",
      "news_entertainment       0.71      0.92      0.80      1051\n",
      "      news_finance       0.80      0.75      0.77       735\n",
      "         news_game       0.91      0.82      0.86       742\n",
      "        news_house       0.92      0.87      0.89       450\n",
      "     news_military       0.88      0.84      0.86       688\n",
      "       news_sports       0.90      0.92      0.91       968\n",
      "        news_story       0.95      0.47      0.63       197\n",
      "         news_tech       0.81      0.86      0.83      1052\n",
      "       news_travel       0.80      0.74      0.77       599\n",
      "        news_world       0.83      0.72      0.77       671\n",
      "             stock       0.00      0.00      0.00         8\n",
      "\n",
      "          accuracy                           0.84     10000\n",
      "         macro avg       0.79      0.76      0.77     10000\n",
      "      weighted avg       0.84      0.84      0.84     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/du/miniforge3/envs/gpt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/du/miniforge3/envs/gpt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/du/miniforge3/envs/gpt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=300)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/du/miniforge3/envs/gpt/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/du/miniforge3/envs/gpt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/du/miniforge3/envs/gpt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "  news_agriculture       0.85      0.88      0.87      3908\n",
      "          news_car       0.92      0.92      0.92      7101\n",
      "      news_culture       0.82      0.85      0.83      5719\n",
      "          news_edu       0.88      0.89      0.89      5376\n",
      "news_entertainment       0.85      0.88      0.86      7908\n",
      "      news_finance       0.82      0.78      0.80      5409\n",
      "         news_game       0.91      0.87      0.89      5899\n",
      "        news_house       0.90      0.91      0.91      3463\n",
      "     news_military       0.86      0.82      0.84      4976\n",
      "       news_sports       0.93      0.93      0.93      7611\n",
      "        news_story       0.83      0.81      0.82      1308\n",
      "         news_tech       0.84      0.85      0.85      8168\n",
      "       news_travel       0.80      0.79      0.79      4252\n",
      "        news_world       0.79      0.80      0.80      5370\n",
      "             stock       0.00      0.00      0.00        70\n",
      "\n",
      "          accuracy                           0.86     76538\n",
      "         macro avg       0.80      0.80      0.80     76538\n",
      "      weighted avg       0.86      0.86      0.86     76538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/du/miniforge3/envs/gpt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: Hivan Du\n",
    "mail: doo@hivan.me\n",
    "LastEditors: Hivan Du\n",
    "LastEditTime: 2023-05-13 07:15:27\n",
    "'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df =  training_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    list(df.embedding.values), df.category, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
