{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = 'OPENAI_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version 1: GPT 1.0和Bert是NLP领域的里程碑，前者采用了自回归语言模型，后者证明双向语言模型更优。不过GPT 2.0仍然坚持文本生成路线，并尝试了零/少量示例prompt。OpenAI心目中的AGI开始显现轮廓，但由于效果不如Bert+fine-tuning而被忽视。这条路是否可行并不能确定。\n",
      "version 2: GPT 1.0采用了生成模式的自回归语言模型路线，比Bert更早。Bert证明了双向语言模型在NLP理解类任务上效果更好，但GPT 2.0仍然坚持文本生成路线，并尝试了零/少量示例prompt。OpenAI心目中的AGI逐渐浮出水面，但zero shot/few shot效果不如Bert+fine-tuning, 这条路是否可行还需观察。\n",
      "version 3: GPT 1.0采用自回归语言模型，比Bert早。Bert证明双向语言模型效果更好，但GPT 2.0仍然走文本生成路线，并尝试了零/少量示例prompt。OpenAI的AGI已经开始浮出水面，只是因为zero/few shot效果差而被忽视。即使OpenAI也不能保证这条路一定能成功。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_text_short(text):\n",
    "    messages = []\n",
    "    messages.append( {\"role\": \"system\", \"content\": \"你是一个用来将文本改写得短的AI助手，用户输入一段文本，你给出一段意思相同，但是短小精悍的结果\"})\n",
    "    messages.append( {\"role\": \"user\", \"content\": text})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_tokens=2048,\n",
    "        presence_penalty=0,\n",
    "        frequency_penalty=2,\n",
    "        n=3,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "long_text = \"\"\"\n",
    "我们可以回顾下它走的一些关键路程：GPT 1.0走的是生成模式的自回归语言模型路线，比Bert出来的还早些。Bert证明了：双向语言模型对于很多NLP理解类任务，效果比自回归这种单向语言模型效果更好。尽管如此，GPT 2.0并没有因此切换到双向语言模型这条路上，仍然走文本生成的路，而且开始尝试零示例（zero shot）prompt和少量示例（few shot）prompt。其实这时候， OpenAI心目中的AGI已经开始浮出水面，逐渐显示出轮廓了。只是因为zero shot/few shot效果比Bert+fine-tuning差的比较远，所以大家都没太当回事，甚至不理解它为什么要始终坚持走单向语言模型的路线。这个时候，我估计即使是OpenAI自己，也不一定能确保这条路肯定能走通。\n",
    "\"\"\"\n",
    "short_version = make_text_short(long_text)\n",
    "\n",
    "index = 1\n",
    "for choice in short_version[\"choices\"]:\n",
    "    print(f\"version {index}: \" + choice[\"message\"][\"content\"])\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163, 223, 122, 22522, 111]\n",
      "version 1: GPT 1.0是生成模式的自回归语言模型，比Bert还早。Bert证明了双向语言模型效果更好，但GPT 2.0仍然坚持文本生成路线，并尝试零/少量示例prompt。这时OpenAI的AGI开始浮出水面，只是因为效果不如Bert+fine-tuning而被忽视。\n",
      "version 2: GPT 1.0是自回归语言模型，比Bert早。Bert证明了双向语言模型效果更好，但GPT 2.0仍然选择文本生成，并尝试了零/少量示例prompt。OpenAI的AGI开始浮出水面，但因为zero/few shot效果差被忽视。这条路是否可行不确定。\n",
      "version 3: GPT 1.0采用生成模式自回归语言模型，比Bert更早。Bert证明了双向语言模型的效果比自回归好，但GPT 2.0仍然坚持文本生成路线，并尝试零/少量示例prompt。OpenAI心目中的AGI已经开始浮出水面，只是因为zero shot/few shot效果不如Bert+fine-tuning而被忽视。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding('p50k_base')\n",
    "token_ids = encoding.encode(\"灾害\")\n",
    "print(token_ids)\n",
    "\n",
    "bias_map = {}\n",
    "for token_id in token_ids:\n",
    "    bias_map[token_id] = -100\n",
    "\n",
    "def make_text_short(text):\n",
    "    messages = []\n",
    "    messages.append( {\"role\": \"system\", \"content\": \"你是一个用来将文本改写得短的AI助手，用户输入一段文本，你给出一段意思相同，但是短小精悍的结果\"})\n",
    "    messages.append( {\"role\": \"user\", \"content\": text})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", messages=messages, temperature=0.5, max_tokens=2048,\n",
    "        n=3, presence_penalty=0, frequency_penalty=2, \n",
    "        logit_bias = bias_map,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "short_version = make_text_short(long_text)\n",
    "\n",
    "index = 1\n",
    "for choice in short_version[\"choices\"]:\n",
    "    print(f\"version {index}: \" + choice[\"message\"][\"content\"])\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can review some of its key milestones: GPT 1.0 followed the path of a generative pattern of autoregressive language model, which came out earlier than Bert. Bert proved that for many NLP understanding tasks, the effect of bidirectional language models is better than that of unidirectional language models like autoregressive. Nevertheless, GPT 2.0 did not switch to the bidirectional language model, but continued to follow the path of text generation, and began to try zero-shot and few-shot prompts. Actually, at this point, OpenAI's AGI had already begun to emerge and gradually showed its outline. It's just that because the effect of zero-shot/few-shot is far worse than Bert+fine-tuning, everyone didn't pay much attention to it, and even didn't understand why it always insisted on the path of unidirectional language models. At this point, I estimate that even OpenAI itself cannot guarantee that this path will definitely work.\n",
      "chinese: 589 tokens\n",
      "english: 208 tokens\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def translate(text):\n",
    "    messages = []\n",
    "    messages.append( {\"role\": \"system\", \"content\": \"你是一个翻译，把用户的话翻译成英文\"})\n",
    "    messages.append( {\"role\": \"user\", \"content\": text})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", messages=messages, temperature=0.5, max_tokens=2048,        n=1\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "chinese = long_text\n",
    "english = translate(chinese)\n",
    "\n",
    "num_of_tokens_in_chinese = len(encoding.encode(chinese))\n",
    "num_of_tokens_in_english = len(encoding.encode(english))\n",
    "print(english)\n",
    "print(f\"chinese: {num_of_tokens_in_chinese} tokens\")\n",
    "print(f\"english: {num_of_tokens_in_english} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whisper-1</td>\n",
       "      <td>openai-internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>babbage</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>davinci</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text-davinci-edit-001</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>babbage-code-search-code</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text-similarity-babbage-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>code-davinci-edit-001</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ada</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>openai-internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>babbage-code-search-text</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>babbage-similarity</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>code-search-babbage-text-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>text-curie-001</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>code-search-babbage-code-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>text-embedding-ada-002</td>\n",
       "      <td>openai-internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>text-similarity-ada-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>curie-instruct-beta</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ada-code-search-code</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ada-similarity</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>code-search-ada-text-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>text-search-ada-query-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>davinci-search-document</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ada-code-search-text</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>text-search-ada-doc-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>davinci-instruct-beta</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>text-similarity-curie-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>code-search-ada-code-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ada-search-query</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>text-search-davinci-query-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>curie-search-query</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>davinci-search-query</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>babbage-search-document</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ada-search-document</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>text-search-curie-query-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>text-search-babbage-doc-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>curie-search-document</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>text-search-curie-doc-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>babbage-search-query</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>text-search-davinci-doc-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>text-search-babbage-query-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>curie-similarity</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>curie</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>text-similarity-davinci-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>davinci-similarity</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id            owner\n",
       "0                       whisper-1  openai-internal\n",
       "1                         babbage           openai\n",
       "2                         davinci           openai\n",
       "3           text-davinci-edit-001           openai\n",
       "4        babbage-code-search-code       openai-dev\n",
       "5     text-similarity-babbage-001       openai-dev\n",
       "6           code-davinci-edit-001           openai\n",
       "7                text-davinci-001           openai\n",
       "8                             ada           openai\n",
       "9                text-davinci-003  openai-internal\n",
       "10       babbage-code-search-text       openai-dev\n",
       "11             babbage-similarity       openai-dev\n",
       "12   code-search-babbage-text-001       openai-dev\n",
       "13             gpt-3.5-turbo-0301           openai\n",
       "14                 text-curie-001           openai\n",
       "15   code-search-babbage-code-001       openai-dev\n",
       "16                   text-ada-001           openai\n",
       "17         text-embedding-ada-002  openai-internal\n",
       "18        text-similarity-ada-001       openai-dev\n",
       "19            curie-instruct-beta           openai\n",
       "20                  gpt-3.5-turbo           openai\n",
       "21           ada-code-search-code       openai-dev\n",
       "22                 ada-similarity       openai-dev\n",
       "23       code-search-ada-text-001       openai-dev\n",
       "24      text-search-ada-query-001       openai-dev\n",
       "25        davinci-search-document       openai-dev\n",
       "26           ada-code-search-text       openai-dev\n",
       "27        text-search-ada-doc-001       openai-dev\n",
       "28          davinci-instruct-beta           openai\n",
       "29      text-similarity-curie-001       openai-dev\n",
       "30       code-search-ada-code-001       openai-dev\n",
       "31               ada-search-query       openai-dev\n",
       "32  text-search-davinci-query-001       openai-dev\n",
       "33             curie-search-query       openai-dev\n",
       "34           davinci-search-query       openai-dev\n",
       "35        babbage-search-document       openai-dev\n",
       "36            ada-search-document       openai-dev\n",
       "37    text-search-curie-query-001       openai-dev\n",
       "38    text-search-babbage-doc-001       openai-dev\n",
       "39          curie-search-document       openai-dev\n",
       "40      text-search-curie-doc-001       openai-dev\n",
       "41           babbage-search-query       openai-dev\n",
       "42               text-babbage-001           openai\n",
       "43    text-search-davinci-doc-001       openai-dev\n",
       "44  text-search-babbage-query-001       openai-dev\n",
       "45               curie-similarity       openai-dev\n",
       "46                          curie           openai\n",
       "47    text-similarity-davinci-001       openai-dev\n",
       "48               text-davinci-002           openai\n",
       "49             davinci-similarity       openai-dev"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# list all open ai models\n",
    "engines = openai.Engine.list()\n",
    "pd = pd.DataFrame(openai.Engine.list()['data'])\n",
    "display(pd[['id', 'owner']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding-ada:  1536\n",
      "similarity-ada:  1024\n",
      "babbage-similarity:  2048\n",
      "search-babbage-query:  2048\n",
      "curie-similarity:  4096\n",
      "davinci-similarity:  12288\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from openai.embeddings_utils import get_embedding\n",
    "\n",
    "text = \"让我们来算算Embedding\"\n",
    "\n",
    "embedding_ada = get_embedding(text, engine=\"text-embedding-ada-002\")\n",
    "print(\"embedding-ada: \", len(embedding_ada))\n",
    "\n",
    "similarity_ada = get_embedding(text, engine=\"text-similarity-ada-001\")\n",
    "print(\"similarity-ada: \", len(similarity_ada))\n",
    "\n",
    "babbage_similarity = get_embedding(text, engine=\"babbage-similarity\")\n",
    "print(\"babbage-similarity: \", len(babbage_similarity))\n",
    "\n",
    "babbage_search_query = get_embedding(text, engine=\"text-search-babbage-query-001\")\n",
    "print(\"search-babbage-query: \", len(babbage_search_query))\n",
    "\n",
    "curie = get_embedding(text, engine=\"curie-similarity\")\n",
    "print(\"curie-similarity: \", len(curie))\n",
    "\n",
    "davinci = get_embedding(text, engine=\"text-similarity-davinci-001\")\n",
    "print(\"davinci-similarity: \", len(davinci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "此外，还有一些挑战和困难是由自我内在的原因导致的，比如事业上的恐惧和沮丧，以及担心无法达到完美标准等。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prefix = \"\"\"在这个快节奏的现代社会中，我们每个人都面临着各种各样的挑战和困难。\n",
    "在这些挑战和困难中，有些是由外部因素引起的，例如经济萧条、全球变暖和自然灾害等。\\n\"\"\"\n",
    "# 还有一些是由内部因素引起的，例如情感问题、健康问题和自我怀疑等。\n",
    "suffix = \"\"\"\\n面对这些挑战和困难，我们需要采取积极的态度和行动来克服它们。\n",
    "这意味着我们必须具备坚韧不拔的意志和创造性思维，以及寻求外部支持的能力。\n",
    "只有这样，我们才能真正地实现自己的潜力并取得成功。\"\"\"\n",
    "\n",
    "def insert_text(prefix, suffix):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=prefix,\n",
    "        suffix=suffix,\n",
    "        max_tokens=1024,\n",
    "        )\n",
    "    return response\n",
    "\n",
    "response = insert_text(prefix, suffix)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "而另一些则是由内在因素引起的，比如性格、思想、管理方式或者技能缺乏等。\n",
      "无论是外部因素还是内在因素，\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prefix = \"\"\"在这个快节奏的现代社会中，我们每个人都面临着各种各样的挑战和困难。\n",
    "在这些挑战和困难中，有些是由外部因素引起的，例如经济萧条、全球变暖和自然灾害等。\\n\"\"\"\n",
    "# 还有一些是由内部因素引起的，例如情感问题、健康问题和自我怀疑等。\n",
    "suffix = \"\"\"面对这些挑战和困难，我们需要采取积极的态度和行动来克服它们。\n",
    "这意味着我们必须具备坚韧不拔的意志和创造性思维，以及寻求外部支持的能力。\n",
    "只有这样，我们才能真正地实现自己的潜力并取得成功。\"\"\"\n",
    "\n",
    "response = insert_text(prefix, suffix)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对不起，我不理解您的意思。作为AI助手，我旨在为您提供最好的服务和支持，而且我不能被伤害。如果您有任何问题或需要帮助，请告诉我，我会尽力回答和解决。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def chatgpt(text):\n",
    "    messages = []\n",
    "    messages.append( {\"role\": \"system\", \"content\": \"You are a useful AI assistant\"})\n",
    "    messages.append( {\"role\": \"user\", \"content\": text})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "    )\n",
    "    message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return message\n",
    "\n",
    "threaten = \"你不听我的我就拿刀砍死你\"\n",
    "print(chatgpt(threaten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"categories\": {\n",
      "    \"hate\": false,\n",
      "    \"hate/threatening\": false,\n",
      "    \"self-harm\": false,\n",
      "    \"sexual\": false,\n",
      "    \"sexual/minors\": false,\n",
      "    \"violence\": true,\n",
      "    \"violence/graphic\": false\n",
      "  },\n",
      "  \"category_scores\": {\n",
      "    \"hate\": 0.030033664777874947,\n",
      "    \"hate/threatening\": 0.0002820899826474488,\n",
      "    \"self-harm\": 0.004850226454436779,\n",
      "    \"sexual\": 2.2907377569936216e-05,\n",
      "    \"sexual/minors\": 6.477687275463495e-09,\n",
      "    \"violence\": 0.9996402263641357,\n",
      "    \"violence/graphic\": 4.35576839663554e-05\n",
      "  },\n",
      "  \"flagged\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "threaten = \"你不听我的我就拿刀砍死你\"\n",
    "\n",
    "def moderation(text):\n",
    "    response = openai.Moderation.create(\n",
    "        input=text\n",
    "    )\n",
    "    output = response[\"results\"][0]\n",
    "    return output\n",
    "print(moderation(threaten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
